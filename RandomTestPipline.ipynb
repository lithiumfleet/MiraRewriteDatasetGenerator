{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "import json\n",
    "from typing import Any, Protocol\n",
    "from DBTool import DatabaseLike, SQliteDB\n",
    "\n",
    "class PiplineLike(Protocol):\n",
    "    def invoke[T](self, samp:T) -> T: ...\n",
    "\n",
    "class Rewriter:\n",
    "    def invoke(self, samp:str) -> str:\n",
    "        pass\n",
    "\n",
    "\n",
    "def init_pipline(file_path:str) -> PiplineLike:\n",
    "    raise NotImplementedError\n",
    "\n",
    "def get_random_conv(db:DatabaseLike, num:int, seed:float=114.514) -> list[Any]:\n",
    "    result = db.random_get(num,seed)\n",
    "    result = [json.loads(res[6]) for res in result]\n",
    "    return result\n",
    "\n",
    "def apply_pipline[T](pipline:PiplineLike, samples:list[T]) -> list[T]:\n",
    "    result = [pipline.invoke(samp) for samp in samples]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQliteDB.connect_db(\"./data/magpieQwen.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'from': 'human',\n",
       "   'value': '假设你需要自助机器人为一个在线销售平台开发一套有利于吸引顾客的自主推荐策略。请根据客户数据（例如浏览历史、购物车项目、购买历史、个人喜好，等等）与产品信息（例如类别信息、销售数量、评价、物品标签，等等）进行输出。'},\n",
       "  {'from': 'gpt',\n",
       "   'value': '开发一套自主推荐策略，旨在提高在线销售平台的顾客满意度和销售量，需要综合考虑客户数据和产品信息。以下是一种可能的策略框架：\\n\\n### 1. 数据收集与预处理\\n- **客户数据**：收集用户的浏览历史、购物车项目、购买历史、个人喜好（如通过问卷调查或用户设置获取）、用户行为（如点击、停留时间、搜索关键词）。\\n- **产品信息**：收集商品的类别信息、销售数量、评价、物品标签、价格、库存状态等。\\n\\n### 2. 数据分析与模型构建\\n- **用户画像构建**：基于用户数据，构建用户画像，包括用户的兴趣偏好、购买力、活跃时间等。\\n- **商品分析**：分析商品的销售趋势、用户评价、热门标签，识别热销商品和潜在爆款。\\n- **推荐算法选择**：根据业务需求和数据特性，选择合适的推荐算法，如协同过滤、基于内容的推荐、深度学习模型（如深度神经网络、卷积神经网络）等。\\n\\n### 3. 推荐策略设计\\n- **个性化推荐**：根据用户画像，为每个用户推荐符合其兴趣和偏好的商品。\\n- **热门商品推荐**：基于销售数据和用户评价，推荐热销商品，吸引新用户。\\n- **交叉销售与向上销售**：根据用户购物车和购买历史，推荐相关或更高级别的商品。\\n- **库存管理推荐**：推荐库存较多的商品，帮助平衡库存。\\n- **时间敏感推荐**：根据用户活跃时间，推送实时优惠或限时折扣。\\n\\n### 4. 实时更新与优化\\n- **实时反馈**：收集用户对推荐商品的反馈，如点击率、购买率、用户评价，用于模型的实时调整。\\n- **A/B测试**：定期进行A/B测试，比较不同推荐策略的效果，优化推荐算法。\\n- **模型迭代**：根据业务需求和市场变化，定期更新推荐模型，引入新的算法或优化现有模型。\\n\\n### 5. 隐私保护与合规\\n- **数据脱敏**：确保在处理用户数据时，遵守数据保护法规，对敏感信息进行脱敏处理。\\n- **透明度与控制**：向用户提供推荐算法的透明度，允许用户控制其数据的使用，如提供推荐偏好设置。\\n\\n通过上述策略，可以构建一个既吸引顾客又尊重用户隐私的自主推荐系统，提升在线销售平台的用户体验和商业价值。'}],\n",
       " [{'from': 'human', 'value': '利用机器学习算法预测用户对于某种商品的偏好'},\n",
       "  {'from': 'gpt',\n",
       "   'value': '预测用户对某种商品的偏好是推荐系统中的一个核心问题，机器学习算法在这一领域有着广泛的应用。以下是一种基于机器学习的用户商品偏好预测流程：\\n\\n1. **数据收集**：首先，需要收集用户行为数据，包括但不限于用户的历史购买记录、浏览记录、搜索记录、评分和评论等。同时，商品信息如类别、价格、描述等也是重要的特征。\\n\\n2. **数据预处理**：对收集到的数据进行清洗，处理缺失值、异常值，进行数据标准化或归一化。同时，将文本数据（如商品描述、用户评论）转化为数值特征，如使用词袋模型、TF-IDF或词嵌入等方法。\\n\\n3. **特征工程**：构建有助于模型预测的特征，如用户和商品的交互特征（如用户对商品的点击率、购买率）、用户行为序列特征（如用户最近浏览的商品类别）、时间特征（如购买时间、季节）等。\\n\\n4. **模型选择与训练**：选择适合的机器学习模型进行训练。常用的模型包括但不限于：\\n   - 协同过滤（Collaborative Filtering）：基于用户-商品评分矩阵，找到相似用户或相似商品，预测用户对未评分商品的评分。\\n   - 矩阵分解（Matrix Factorization）：如SVD、NMF，将用户-商品评分矩阵分解为用户和商品的低维特征表示，预测用户对商品的评分。\\n   - 深度学习模型：如深度神经网络（DNN）、卷积神经网络（CNN）、循环神经网络（RNN）、长短时记忆网络（LSTM）、Transformer等，可以处理更复杂的特征和序列数据。\\n   - 集成学习模型：如随机森林（Random Forest）、梯度提升树（Gradient Boosting Tree，如XGBoost、LightGBM）等，可以处理高维稀疏数据。\\n\\n5. **模型评估**：使用交叉验证、A/B测试等方法评估模型的预测性能，常用的评估指标包括准确率、召回率、F1分数、AUC-ROC曲线下的面积等。\\n\\n6. **模型优化与调参**：根据评估结果，调整模型参数，优化模型性能。\\n\\n7. **模型部署与监控**：将训练好的模型部署到生产环境，实时或定期预测用户对商品的偏好，并监控模型性能，及时更新模型。\\n\\n通过以上步骤，可以构建一个基于机器学习的用户商品偏好预测系统，为用户提供个性化的商品推荐。'}],\n",
       " [{'from': 'human',\n",
       "   'value': '开发一个在Python中利用Dask和Pandas库的大数据处理程序，需要高效的管理和操作带有数十亿条记录的大型数据集。设计的程序应能执行如下操作：'},\n",
       "  {'from': 'gpt',\n",
       "   'value': '为了开发一个使用Dask和Pandas库的大数据处理程序，我们首先需要安装Dask库。在你的命令行中运行以下命令：\\n\\n```\\npip install dask[complete] pandas\\n```\\n\\n接下来，我们将创建一个Python程序，该程序将使用Dask和Pandas库来处理大型数据集。以下是一个示例程序，它将执行以下操作：\\n\\n1. 从CSV文件中读取数据。\\n2. 对数据进行筛选、排序和分组。\\n3. 计算数据的统计信息。\\n4. 将处理后的数据保存到新的CSV文件中。\\n\\n```python\\nimport dask.dataframe as dd\\nimport pandas as pd\\n\\n# 1. 从CSV文件中读取数据\\n# 请将以下路径替换为你的CSV文件路径\\ncsv_file_path = \"path/to/your/large_dataset.csv\"\\ndf = dd.read_csv(csv_file_path)\\n\\n# 2. 对数据进行筛选、排序和分组\\n# 假设我们有一个名为\\'column1\\'的列，我们想筛选出其中值大于10的行\\nfiltered_df = df[df[\\'column1\\'] > 10]\\n\\n# 对筛选后的数据按\\'column2\\'列进行排序\\nsorted_df = filtered_df.compute().sort_values(by=\\'column2\\')\\n\\n# 对排序后的数据按\\'column3\\'列进行分组，并计算\\'column1\\'的平均值\\ngrouped_df = sorted_df.groupby(\\'column3\\').agg({\\'column1\\': \\'mean\\'}).reset_index()\\n\\n# 3. 计算数据的统计信息\\n# 计算\\'column1\\'的总和、最小值、最大值和标准差\\ncolumn1_sum = grouped_df[\\'column1\\'].sum()\\ncolumn1_min = grouped_df[\\'column1\\'].min()\\ncolumn1_max = grouped_df[\\'column1\\'].max()\\ncolumn1_std = grouped_df[\\'column1\\'].std()\\n\\n# 4. 将处理后的数据保存到新的CSV文件中\\n# 请将以下路径替换为你想要保存新CSV文件的路径\\noutput_csv_file_path = \"path/to/your/processed_dataset.csv\"\\ngrouped_df.to_csv(output_csv_file_path, index=False)\\n\\n# 打印统计信息\\nprint(f\"Column1 sum: {column1_sum}\")\\nprint(f\"Column1 min: {column1_min}\")\\nprint(f\"Column1 max: {column1_max}\")\\nprint(f\"Column1 std: {column1_std}\")\\n```\\n\\n请注意，你需要将上述代码中的`csv_file_path`和`output_csv_file_path`替换为你的实际文件路径。此外，你还需要根据你的数据集更改列名（例如`column1`、`column2`和`column3`）。\\n\\n这个程序将使用Dask和Pandas库高效地处理大型数据集。Dask会自动将数据集分割成多个分区，并在多个CPU核心上并行处理数据，从而提高处理速度。'}]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_conv(db, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "\n",
    "db = connect_db(\"./data/magpieQwen.db\")\n",
    "pipline = init_pipline(\"./prompt.json\")\n",
    "samples = get_random_conv(db, 10)\n",
    "results = apply_pipline(pipline, samples)\n",
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
